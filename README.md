# CPU vs GPU ML Inference Benchmark

A comprehensive Python tool for comparing machine learning inference performance between CPU and GPU (specifically optimized for NVIDIA GTX 750 Ti). This benchmark visualizes the speed advantage of GPU acceleration for neural network inference.

![Performance Comparison](https://img.shields.io/badge/GPU_Speedup-4.9x-brightgreen)
![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange)
![CUDA](https://img.shields.io/badge/CUDA-11.8-purple)

## ðŸ“‹ Overview

This project benchmarks and compares the performance of CPU vs GPU for machine learning inference tasks. It's specifically tested and optimized for the NVIDIA GTX 750 Ti (2GB VRAM) but works with any CUDA-compatible GPU.

### Key Features
- âœ… **CPU vs GPU performance comparison** with detailed metrics
- âœ… **Interactive visualization** with matplotlib
- âœ… **Batch size analysis** to find optimal configurations
- âœ… **GTX 750 Ti optimized** for 2GB VRAM constraints
- âœ… **Real-time progress tracking** with tqdm
- âœ… **Professional reporting** with multiple visualization formats
- âœ… **Automatic GPU detection** and configuration


## ðŸš€ Quick Start

### Prerequisites
- NVIDIA GPU with CUDA support (GTX 750 Ti in my case from my OLD work pc)
- Windows 10/11 or Linux with Python 3.8+
- NVIDIA drivers installed
- At least 8GB system RAM


